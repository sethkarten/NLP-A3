main.py --train --cond --batch_method translation --attn

Building data from ./data...
      batch_size: 20
batch_size_valid: 60
    batch_method: translation      (no sorting by target lengths)
          device: cpu
  is_conditional: True

15 batches
5 batches

vocab_size: 1282

train.txt
              # words: 6681
               # seqs: 300
  avg/max/min lengths: 22/72/3

src-train.txt
              # words: 6081
               # seqs: 300
  avg/max/min lengths: 20/70/1

Seq2Seq
      # parameters: 522682
        vocab_size: 1282
               dim: 100
          # layers: 2
    is_conditional: 1
     bidirectional: 0
        use_bridge: 0
     use_attention: 1

Control
            lr: 20.00
          bptt: 35

| epoch   1 |    20/   29 batches | lr 20.00 | ms/batch 105.43 | loss  7.52 | ppl  1839.65
-----------------------------------------------------------------------------------------
| end of epoch   1 | time:  3.78s | valid loss  5.93 | valid ppl   375.58 | valid sqxent   126.10
-----------------------------------------------------------------------------------------
| epoch   2 |    20/   29 batches | lr 20.00 | ms/batch 102.41 | loss  5.90 | ppl   365.71
-----------------------------------------------------------------------------------------
| end of epoch   2 | time:  3.69s | valid loss  5.59 | valid ppl   267.66 | valid sqxent   118.89
-----------------------------------------------------------------------------------------
| epoch   3 |    20/   29 batches | lr 20.00 | ms/batch 104.81 | loss  5.20 | ppl   181.90
-----------------------------------------------------------------------------------------
| end of epoch   3 | time:  3.72s | valid loss  5.46 | valid ppl   235.79 | valid sqxent   116.20
-----------------------------------------------------------------------------------------
| epoch   4 |    20/   29 batches | lr 20.00 | ms/batch 103.60 | loss  4.77 | ppl   117.51
-----------------------------------------------------------------------------------------
| end of epoch   4 | time:  3.68s | valid loss  5.45 | valid ppl   233.82 | valid sqxent   116.02
-----------------------------------------------------------------------------------------
| epoch   5 |    20/   29 batches | lr 20.00 | ms/batch 101.24 | loss  4.53 | ppl    93.15
-----------------------------------------------------------------------------------------
| end of epoch   5 | time:  3.67s | valid loss  5.39 | valid ppl   219.60 | valid sqxent   114.68
-----------------------------------------------------------------------------------------
| epoch   6 |    20/   29 batches | lr 20.00 | ms/batch 99.65 | loss  4.40 | ppl    81.59
-----------------------------------------------------------------------------------------
| end of epoch   6 | time:  3.70s | valid loss  5.37 | valid ppl   215.85 | valid sqxent   114.32
-----------------------------------------------------------------------------------------
| epoch   7 |    20/   29 batches | lr 20.00 | ms/batch 101.39 | loss  4.24 | ppl    69.41
-----------------------------------------------------------------------------------------
| end of epoch   7 | time:  3.68s | valid loss  5.36 | valid ppl   212.89 | valid sqxent   114.02
-----------------------------------------------------------------------------------------
| epoch   8 |    20/   29 batches | lr 20.00 | ms/batch 99.71 | loss  4.12 | ppl    61.44
-----------------------------------------------------------------------------------------
| end of epoch   8 | time:  3.68s | valid loss  5.19 | valid ppl   180.06 | valid sqxent   110.46
-----------------------------------------------------------------------------------------
| epoch   9 |    20/   29 batches | lr 20.00 | ms/batch 100.95 | loss  3.99 | ppl    54.10
-----------------------------------------------------------------------------------------
| end of epoch   9 | time:  3.68s | valid loss  5.12 | valid ppl   166.97 | valid sqxent   108.86
-----------------------------------------------------------------------------------------
| epoch  10 |    20/   29 batches | lr 20.00 | ms/batch 102.02 | loss  3.93 | ppl    51.09
-----------------------------------------------------------------------------------------
| end of epoch  10 | time:  3.71s | valid loss  5.11 | valid ppl   165.32 | valid sqxent   108.64
-----------------------------------------------------------------------------------------
=========================================================================================
| End of training | final loss  5.11 | final ppl   165.32 | final sqxent   108.64
=========================================================================================
00:00:38
